This is a project for the BlueDot Alignment course attempting to automate interpretability by fully explaining neural networks using ChatGPT.
This is attempted on 2 problems: the XOR problem and the MNIST dataset.

****XOR Neural Networks****  
The XOR (exclusive or) problem is defined as follows:  
2 binary inputs   
1 output  

0 xor 0 = 0  
0 xor 1 = 1  
1 xor 0 = 1  
1 xor 1 = 0  

Although it seems obvious in today's neural network based society that neural networks can solve this problem, in 1969 Minsky and Papert proved that a single layered neural network could not solve this problem. This was taken by the community as a reflection of neural networks as a whole and so the first "ai winter" ensued. 

Naturally this is no longer the case, and the point of this project is to interpret end-to-end the full functionality of these xor networks end-to-end. 
Once we understand how to do that, we'll move onto understanding how to get this working on the famous MNIST dataset.

